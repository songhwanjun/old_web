[{"authors":["admin"],"categories":null,"content":"Currently, I am a Research Scientist at NAVER AI Lab. I graduated with my PhD in Feburary 2021 from the Graduate School of Knowledge Service Engineering at KAIST under the supervision of Prof. Jae-Gil Lee, which is leading Data Mining Lab.\nLast year, I worked as a research intern at Google Research (2020 June \u0026ndash; December) under the supervision of two hosts, Prof. Ming-Hsuan Yang and Dr. Eunyoung Kim, and two mentors, Dr. Deqing Sun and Dr. Varun Jampani.\nMy general research interests lie in improving the performance of machine learning techniques under real-world scenarios. I am particularly interested in designing more advanced approaches to handle large-scale and noisy data, which are two main real-world challenges to hinder the practical use of ML approaches.\nIn NAVER AI Lab, there are many open opsition for research internship. If you are interested in our group, please see my previous papers (especially ViDT and some works for noisy labels) and send an email to me with your CV and research interest (contact: hwanjun.song@navercorp.com)\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Currently, I am a Research Scientist at NAVER AI Lab. I graduated with my PhD in Feburary 2021 from the Graduate School of Knowledge Service Engineering at KAIST under the supervision of Prof.","tags":null,"title":"Hwanjun Song","type":"authors"},{"authors":["Hwanjun Song","Deqing Sun","Sanghyuk Chun","Varun Jampani","Dongyoon Han","Byeongho Heo","Wonjae Kim","Ming-Hsuan Yang"],"categories":null,"content":"","date":1642377600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642377600,"objectID":"691313087bbd89ba2f0e065588f71f81","permalink":"https://example.com/publication/2022iclr_vidt/","publishdate":"2022-01-17T00:00:00Z","relpermalink":"/publication/2022iclr_vidt/","section":"publication","summary":"Transformers are transforming the landscape of computer vision, especially for recognition tasks. Detection transformers are the first fully end-to-end learning systems for object detection, while vision transformers are the first fully transformer-based architecture for image classification. In this paper, we integrate Vision and Detection Transformers (ViDT) to build an effective and efficient object detector. ViDT introduces a reconfigured attention module to extend the recent Swin Transformer to be a standalone object detector, followed by a computationally efficient transformer decoder that exploits multi-scale features and auxiliary techniques essential to boost the detection performance without much increase in computational load. Extensive evaluation results on the Microsoft COCO benchmark dataset demonstrate that ViDT obtains the best AP and latency trade-off among existing fully transformer-based object detectors, and achieves 49.2AP owing to its high scalability for large models. We will release the code and trained models at https://github.com/naver-ai/vidt.","tags":null,"title":"ViDT: An Efficient and Effective Fully Transformer-based Object Detector (ICLR 2022)","type":"publication"},{"authors":["Yooju Shin","Susik Yoon","Sundong Kim","Hwanjun Song","Jae-Gil Lee","Byung Suk Lee"],"categories":null,"content":"","date":1642291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642291200,"objectID":"4482a2d58e24191a572d15119565d113","permalink":"https://example.com/publication/2022iclr_tclp/","publishdate":"2022-01-16T00:00:00Z","relpermalink":"/publication/2022iclr_tclp/","section":"publication","summary":"Time-series data are ubiquitous these days, but lack of the labels in time-series data is regarded as a hurdle for its broad applicability. Meanwhile, active learning has been successfully adopted to reduce the labeling efforts in various tasks. Thus, this paper addresses an important issue, time-series active learning. Inspired by the temporal coherence in time-series data, where consecutive data points tend to have the same label, our label propagation framework, called TCLP, automatically assigns a queried label to the data points within an accurately estimated time-series segment, thereby significantly boosting the impact of an individual query. Compared with traditional time-series active learning, TCLP is shown to improve the classification accuracy by up to 5.9 times when only 0.4% of data points in the entire time series are queried for their labels.","tags":null,"title":"Coherence-based Label Propagation over Time Series for Accelerated Active Learning (ICLR 2022)","type":"publication"},{"authors":["Minseok Kim","Hwanjun Song","Yooju Shin","Dongmin Park","Kijung Shin","Jae-Gil Lee"],"categories":null,"content":"","date":1638748800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638748800,"objectID":"1e6439a83b4802e6487a7cca99ca4a29","permalink":"https://example.com/publication/2022melon_aaai/","publishdate":"2021-12-06T00:00:00Z","relpermalink":"/publication/2022melon_aaai/","section":"publication","summary":"Online recommender systems should be always aligned with users' current interest to accurately suggest items that each user would like. Since user interest usually evolves over time, the update strategy should be flexible to quickly catch users' current interest from continuously generated new user-item interactions. Existing update strategies focus either on the importance of each user-item interaction or the learning rate for each recommender parameter, but such one-directional flexibility is insufficient to adapt to varying relationships between interactions and parameters. In this paper, we propose MeLON, a meta-learning based novel online recommender update strategy that supports two-directional flexibility. It is featured with an adaptive learning rate for each parameter-interaction pair for inducing a recommender to quickly learn users' up-to-date interest. The procedure of MeLON is optimized following a meta-learning approach; it learns how a recommender learns to generate the optimal learning rates for future updates. Specifically, MeLON first enriches the meaning of each interaction based on previous interactions and identifies the role of each parameter for the interaction; and then combines these two pieces of information to generate an adaptive learning rate. Theoretical analysis and extensive evaluation on three real-world online recommender datasets validate the effectiveness of MeLON.","tags":null,"title":"Meta-Learning for Online Update of Recommender Systems (AAAI 2022)","type":"publication"},{"authors":["Doyoung Kim","Hyangsuk Min","Youngeun Nam","Hwanjun Song","Susik Yoon","Minseok Kim","Jae-Gil Lee"],"categories":null,"content":"","date":1638662400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638662400,"objectID":"be2848cfef9442ac0ef1dcdf618b3c21","permalink":"https://example.com/publication/2022covid_aaai/","publishdate":"2021-12-05T00:00:00Z","relpermalink":"/publication/2022covid_aaai/","section":"publication","summary":"Assessing the impact of the COVID-19 crisis on economies is fundamental to tailor the responses of the governments to recover from the crisis. In this paper, we present a novel approach to assessing the economic impact with a large-scale credit card transaction dataset at a fine granularity. For this purpose, we develop a fine-grained economic-epidemiological modeling framework COVID-EENet, which is featured with a two-level deep neural network. In support of the fine-grained EEM, COVID-EENet learns the impact of nearby mass infection cases on the changes of local economies in each district. Through the experiments using the nationwide dataset, given a set of active mass infection cases, COVID-EENet is shown to precisely predict the sales changes in two or four weeks for each district and business category. Therefore, policymakers can be informed of the predictive impact to put in the most effective mitigation measures. Overall, we believe that our work opens a new perspective of using financial data to recover from the economic crisis. For public use in this urgent problem, we release the source code at https://bit.ly/covideenet.","tags":null,"title":"COVID-EENet: Predicting Fine-Grained Impact of COVID-19 on Local Economies (AAAI 2022)","type":"publication"},{"authors":["Hwanjun Song","Eunyoung Kim","Varun Jampani","Deqing Sun","Jae-Gil Lee","Ming-Hsuan Yang"],"categories":null,"content":"","date":1633996800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633996800,"objectID":"d322ab836c33db9e0ad7e19fe39cdc82","permalink":"https://example.com/publication/2021bmvc_medusa/","publishdate":"2021-10-12T00:00:00Z","relpermalink":"/publication/2021bmvc_medusa/","section":"publication","summary":"We propose a generic framework MEDUSA (Multimodal Estimated-Depth Unification with Self-Attention) to fuse RGB and depth information using multimodal transformers in the context of object detection. Unlike previous methods that use the depth measured from various physical sensors such as Kinect and Lidar, we show that the depth maps inferred by a monocular depth estimator can play an important role to enhance the performance of modern object detectors. In order to make use of the estimated depth, \\algname{} encompasses a robust feature extraction phase, followed by multimodal transformers for RGB-D fusion. The main strength of \\algname{} lies in its broad applicability for any existing large-scale RGB datasets including PASCAL VOC and Microsoft COCO. Extensive experiments with three datasets show that \\algname{} achieves higher precision than several strong baselines.","tags":null,"title":"Exploiting Scene Depth for Object Detection with Multimodal Transformers (BMVC 2021)","type":"publication"},{"authors":["Dongmin Park","Hwanjun Song","Minseok Kim","Jae-Gil Lee"],"categories":null,"content":"","date":1633392000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633392000,"objectID":"3c5891458a601ef53c4f8fe957a79359","permalink":"https://example.com/publication/2021neurips_taufe/","publishdate":"2021-10-05T00:00:00Z","relpermalink":"/publication/2021neurips_taufe/","section":"publication","summary":"A deep neural network (DNN) has achieved great success in many machine learning tasks by virtue of its high expressive power. However, its prediction can be easily biased to undesirable features, which are not essential for solving the target task and are even imperceptible to a human, thereby resulting in poor generalization. Leveraging plenty of undesirable features in out-of-distribution (OOD) examples has emerged as a potential solution for de-biasing such features, and a recent study shows that softmax-level calibration of OOD examples can successfully remove the contribution of undesirable features to the last fully-connected layer of a classifier. However, its applicability is confined to the classification task, and its impact on a DNN feature extractor is not properly investigated. In this paper, we propose TAUFE, a novel regularizer that deactivates many undesirable features using OOD examples in the feature extraction layer and thus removes the dependency on the task-specific softmax layer. To show the task-agnostic nature of TAUFE, we rigorously validate its performance on three tasks, classification, regression, and a mix of them, on CIFAR-10, CIFAR-100, ImageNet, CUB200, and CAR datasets. The results demonstrate that TAUFE consistently outperforms the state-of-the-art method as well as the baselines without regularization.","tags":null,"title":"Task-Agnostic Undesirable Feature Deactivation Using Out-of-Distribution Data (NeurIPS 2021)","type":"publication"},{"authors":["Hwanjun Song","Minseok Kim","Dongmin Park","Yooju Shin","Jae-Gil Lee"],"categories":null,"content":"","date":1621209600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621209600,"objectID":"8499230c4987720ac13ae34431d3174a","permalink":"https://example.com/publication/2021kdd_morph/","publishdate":"2021-05-17T00:00:00Z","relpermalink":"/publication/2021kdd_morph/","section":"publication","summary":"Real-world data inevitably contains noisy labels, which induce the poor generalization of deep neural networks. It is known that the network typically begins to rapidly memorize false-labeled samples after a certain point of training. Thus, to counter the label noise challenge, we propose a novel self-transitional learning method called MORPH, which automatically switches its learning phase at the transition point from seeding to evolution. In the seeding phase, the network is updated using all the samples to collect a seed of clean samples. Then, in the evolution phase, the network is updated using only the set of arguably clean samples, which precisely keeps expanding by the updated network. Thus, MORPH effectively avoids the overfitting to false-labeled samples throughout the entire training period. Extensive experiments using five real-world or synthetic benchmark datasets demonstrate substantial improvements over state-of-the-art methods in terms of robustness and efficiency.","tags":null,"title":"Robust Learning by Self-Transition for Handling Noisy Labels (KDD 2021)","type":"publication"},{"authors":["Jae-Gil Lee","Yuji Roh","Hwanjun Song","Steven Euijong Whang"],"categories":null,"content":"","date":1621123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621123200,"objectID":"3e9b8ecf9f3aac3c9a8bdbf90c389211","permalink":"https://example.com/publication/2021kdd_tutorial/","publishdate":"2021-05-16T00:00:00Z","relpermalink":"/publication/2021kdd_tutorial/","section":"publication","summary":"Responsible AI becomes critical where robustness and fairness must be satisfied together. Traditionally, the two topics have been studied by different communities for different applications. Robust training is designed for noisy or poisoned data where image data is typically considered. In comparison, fair training primarily deals with biased data where structured data is typically considered. Nevertheless, robust training and fair training are fundamentally similar in considering that both of them aim at fixing the inherent flaws of real-world data. In this tutorial, we first cover state-of-the-art robust training techniques where most of the research is on combating various label noises. In particular, we cover label noise modeling, robust training approaches, and real-world noisy data sets. Then, proceeding to the related fairness literature, we discuss pre-processing, in-processing, and post-processing unfairness mitigation techniques, depending on whether the mitigation occurs before, during, or after the model training. Finally, we cover the recent trend emerged to combine robust and fair training in two flavors - the former is to make the fair training more robust (i.e., robust fair training), and the latter is to consider robustness and fairness as two equals to incorporate them into a holistic framework. This tutorial is indeed timely and novel because the convergence of the two topics is increasingly common, but yet to be addressed in tutorials. The tutors have extensive experience publishing papers in top-tier machine learning and data mining venues and developing machine learning platforms.","tags":null,"title":"Machine Learning Robustness, Fairness, and their Convergence (KDD 2021)","type":"publication"},{"authors":["Hwanjun Song","Minseok Kim","Dongmin Park","Yooju Shin","Jae-Gil Lee"],"categories":null,"content":"","date":1617840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617840000,"objectID":"4757bffd3cae1922b25d54de17805afb","permalink":"https://example.com/publication/2021arxiv_survey/","publishdate":"2021-04-08T00:00:00Z","relpermalink":"/publication/2021arxiv_survey/","section":"publication","summary":"Deep learning has achieved remarkable success in numerous domains with help from large amounts of big data. However, the quality of data labels is a concern because of the lack of high-quality labels in many real-world scenarios. As noisy labels severely degrade the generalization performance of deep neural networks, learning from noisy labels (robust training) is becoming an important task in modern deep learning applications. In this survey, we first describe the problem of learning with label noise from a supervised learning perspective. Next, we provide a comprehensive review of 57 state-of-the-art robust training methods, all of which are categorized into five groups according to their methodological difference, followed by a systematic comparison of six properties used to evaluate their superiority. Subsequently, we perform an in-depth analysis of noise rate estimation and summarize the typically used evaluation methodology, including public noisy datasets and evaluation metrics. Finally, we present several promising research directions that can serve as a guideline for future studies. All the contents will be available at https://github.com/songhwanjun/Awesome-Noisy-Labels.","tags":null,"title":"Learning from Noisy Labels with Deep Neural Networks: A Survey (Arxiv 2021, Under Revision)","type":"publication"},{"authors":["Hwanjun Song"],"categories":null,"content":"","date":1614470400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614470400,"objectID":"c5c6c85d03e6c975d13b23cc2c949b4e","permalink":"https://example.com/publication/2020disertation/","publishdate":"2020-12-16T00:00:00Z","relpermalink":"/publication/2020disertation/","section":"publication","summary":"Deep learning has achieved remarkable success in numerous domains with help from large amounts of big data. However, the quality of data labels is a concern because of the lack of high-quality labels in many real-world scenarios. In the presence of noisy labels, the generalization performance of deep neural networks drastically falls down owing to their high capacity to overfit any noise labels. This overfitting issue still remains even with various conventional regularization techniques, such as dropout and batch normalization. Therefore, learning from noisy labels (robust training) has recently become one of the most active research topics in the machine learning community. In the first part, we provide the problem statement for supervised learning with noisy labels, followed by a thorough survey on the advance in recent deep learning techniques for overcoming noisy labels; we surveyed recent studies by recursively tracking relevant bibliographies in papers published at premier research conferences. Throughout this survey, we note that the main research effort has been made to answer the two following questions - (1) how to minimize the negative in uence of false-labeled samples by adjusting their loss values? and (2) how to identify true-labeled samples from noisy data?, both of which have been well-explored respectively by the two research directions, namely, loss adjustment and sample selection. In the second part, we mainly focus on understanding the pros and cons of the aforementioned research directions and, subsequently, propose a hybrid learning approach called SELFIE that takes advantage of both loss adjustment and sample selection. For the hybrid approach, a new concept of a refurbishable sample is introduced to classify the sample whose loss can be correctly adjusted with high precision. The loss of refurbishable samples is adjusted First and then combined with that of the samples chosen by a representative sample selection criterion called small-loss trick. To validate the superiority of SELFIE, we conducted extensive experimentation using both real-world or synthetic noisy datasets. The results empirically verify that SELFIE significantly outperforms state-of-the-art methods in test error by up to 10.5 percentage point. In the third part, we take a closer look at the small-loss trick adopted by SELFIE for sample selection. We argue that the trick misclassifies many false-labeled samples as clean samples in realistic noise. Hence, we present a new sample selection method called Prestopping, which derives a collection of true-labeled samples by using the early stopping mechanism. Prestopping obtains an initial safe set by stopping its learning process before the network begins to rapidly memorize false-labeled samples and, subsequently, resumes training to improve the quality and quantity of the set gradually. Compared with state-of-the-art methods including SELFIE, Prestopping further improves the test error by up to 18.1 percentage point on four real-world or synthetic noisy datasets. The main technical challenge in Prestopping is determining the best stop point for its phase transition (we call it a best transition point). In Prestopping, a clean validation set or a known true noise rate is used for supervision, but they are usually hard to acquire in practice. In the last part, we introduce a novel self-transitional learning approach called MORPH, which automatically switches its learning phase at the best transition point without any supervision. Extensive experiments using five benchmark datasets demonstrate that only MORPH succeeds to construct a collection of almost true-labeled samples in a wide range of noise types. We leave the incorporation of SELFIE with MORPH as future work.","tags":null,"title":"Robust Learning under Label Noise with Deep Neural Networks (PhD Dissertation)","type":"publication"},{"authors":["Minseok Kim","Hwanjun Song","Doyoung Kim","Kijung Shin","Jae-Gil Lee"],"categories":null,"content":"","date":1612656000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612656000,"objectID":"8ecd2ac4e8b03ee9062e5d457dbca9d7","permalink":"https://example.com/publication/2021aaai_premere/","publishdate":"2020-12-01T00:00:00Z","relpermalink":"/publication/2021aaai_premere/","section":"publication","summary":"Point-of-interest (POI) recommendation has become an important research topic in these days. The user check-in history used as the input to POI recommendation is very imbalanced and noisy because of sparse and missing check-ins. Although sample reweighting is commonly adopted for addressing this challenge with the input data, its fixed weighting scheme is often inappropriate to deal with different characteristics of users or POIs. Thus, in this paper, we propose PREMERE, an adaptive weighting scheme based on meta-learning. Because meta-data is typically required by meta-learning but is inherently hard to obtain in POI recommendation, we self-generate the meta-data via self-ensembling. Furthermore, the meta-model architecture is extended to deal with the scarcity of check-ins. Thorough experiments show that replacing a weighting scheme with PREMERE boosts the performance of the state-of-the-art recommender algorithms by 2.36–26.9% on three benchmark datasets.","tags":null,"title":"PREMERE: Meta-Reweighting via Self-Ensembling for Point-of-Interest Recommendation (AAAI 2021)","type":"publication"},{"authors":["Hwanjun Song","Minseok Kim","Sundong Kim","Jae-Gil Lee"],"categories":null,"content":"","date":1594944000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594944000,"objectID":"2bbeb8e242838053624af1fcd60bb781","permalink":"https://example.com/publication/2020cikm_carpediem/","publishdate":"2020-07-17T00:00:00Z","relpermalink":"/publication/2020cikm_carpediem/","section":"publication","summary":"The accuracy of deep neural networks is significantly affected by how well mini-batches are constructed during the training step. In this paper, we propose a novel adaptive batch selection algorithm called RecencyBias that exploits the uncertain samples predicted inconsistently in recent iterations. The historical label predictions of each training sample are used to evaluate its predictive uncertainty within a sliding window. Then, the sampling probability for the next mini-batch is assigned to each training sample in proportion to its  predictive uncertainty. By taking advantage of this design, Recency Bias not only accelerates the training step but also achieves a more accurate network. We demonstrate the superiority of Recency Bias by extensive evaluation on two independent tasks. Compared with existing batch selection methods, the results showed that Recency Bias reduced the test error by up to 20.97% in a fixed wall-clock training time. At the same time, it improved the training time by up to 59.32% to reach the same test error.","tags":null,"title":"Carpe Diem, Seize the Samples Uncertain \"At the Moment\" for Adaptive Batch Selection (CIKM 2020)","type":"publication"},{"authors":["Hwanjun Song","Sundong Kim","Minseok Kim","Jae-Gil Lee"],"categories":null,"content":"","date":1594857600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594857600,"objectID":"b3ee87337bec1e64ae65cb7780bdb038","permalink":"https://example.com/publication/2020ml_ada/","publishdate":"2020-07-17T00:00:00Z","relpermalink":"/publication/2020ml_ada/","section":"publication","summary":"Neural networks converge faster with help from a smart batch selection strategy. In this regard, we propose Ada-Boundary, a novel and simple adaptive batch selection algorithm that constructs an effective mini-batch according to the learning progress of the model. Our key idea is to exploit confusing samples for which the model cannot predict labels with high confidence. Thus, samples near the current decision boundary are considered to be the most effective for expediting convergence. Taking advantage of this design, Ada-Boundary maintained its dominance for various degrees of training difficulty. We demonstrate the advantage of Ada-Boundary by extensive experimentation using CNNs with five benchmark data sets. Ada-Boundary was shown to produce a relative improvement in test errors by up to 31.80% compared with the baseline for a fixed wall-clock training time, thereby achieving a faster convergence speed.","tags":null,"title":"Ada-Boundary: Accelerating DNN Training via Adaptive Boundary Batch Selection (Machine Learning 2020, SCIE IF=2.672, ECML-PKDD Journal Track)","type":"publication"},{"authors":["Hwanjun Song","Minseok Kim","Dongmin Park","Jae-Gil Lee"],"categories":null,"content":"","date":1594857600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594857600,"objectID":"fea2d4c3722982ba572b7e01aaf2588a","permalink":"https://example.com/publication/2020arxiv_survey/","publishdate":"2020-07-16T00:00:00Z","relpermalink":"/publication/2020arxiv_survey/","section":"publication","summary":"Deep learning has achieved remarkable success in numerous domains with help from large amounts of big data. However, the quality of data labels is a concern because of the lack of high-quality labels in many real-world scenarios. As noisy labels severely degrade the generalization performance of deep neural networks, learning from noisy labels (robust training) is becoming an important task in modern deep learning applications. In this survey, we first describe the problem of learning with label noise from a supervised learning perspective. Next, we provide a comprehensive review of 46 state-of-the-art robust training methods, all of which are categorized into seven groups according to their methodological difference, followed by a systematic comparison of six properties used to evaluate their superiority. Subsequently, we summarize the typically used evaluation methodology, including public noisy datasets and evaluation metrics. Finally, we present several promising research directions that can serve as a guideline for future studies.","tags":null,"title":"Learning from Noisy Labels with Deep Neural Networks: A Survey (Arxiv 2020, Under Review)","type":"publication"},{"authors":["Minseok Kim","Junhyeok Kang","Doyoung Kim","Hwanjun Song","Hyangsuk Min","Youngeun Nam","Dongmin Park","Jae-Gil Lee"],"categories":null,"content":"","date":1594771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594771200,"objectID":"eb0bf35f66d270bfaf939de171680077","permalink":"https://example.com/publication/2020kdd_hicovidnet/","publishdate":"2020-07-15T00:00:00Z","relpermalink":"/publication/2020kdd_hicovidnet/","section":"publication","summary":"The escalating crisis of COVID-19 has put people all over the world in danger. Owing to the high contagion rate of the virus, COVID-19 cases continue to increase globally. To further suppress the threat of the COVID-19 pandemic and minimize its damage, it is imperative that each country monitors inbound travelers. Moreover, given that resources for quarantine are often limited, they must be carefully allocated. In this paper, to aid in such allocation by predicting the number of inbound COVID-19 cases, we propose Hi-COVIDNet, which takes advantage of the geographic hierarchy. Hi-COVIDNet is based on a neural network with two-level components, namely, country-level and continent-level encoders, which understand the complex relationships among foreign countries and derive their respective contagion risk to the destination country. An in-depth case study in South Korea with real-world COVID-19 datasets confirmed the effectiveness and practicality of Hi-COVIDNet. The source code and datasets are available at https://bit.ly/3gDLsCT.","tags":null,"title":"Hi-COVIDNet: Deep Learning Approach to Predict Inbound COVID-19 Patients and Case Study in South Korea (KDD 2020)","type":"publication"},{"authors":["Hwanjun Song","Minseok Kim","Dongmin Park","Jae-Gil Lee"],"categories":null,"content":"","date":1594600800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594600800,"objectID":"d971fa0f49ba6aefb56c61abb07b67e1","permalink":"https://example.com/publication/2019arxiv_prestopping/","publishdate":"2020-07-13T00:40:00Z","relpermalink":"/publication/2019arxiv_prestopping/","section":"publication","summary":"Noisy labels are very common in real-world training data, which lead to poor generalization on test data because of overfitting to the noisy labels. In this paper, we claim that such overfitting can be avoided by “early stopping” training a deep neural network before the noisy labels are severely memorized. Then, we resume training the early stopped network using a “maximal safe set,” which maintains a collection of almost certainly true-labeled samples at each epoch since the early stop point. Putting them all together, our novel two-phase training method, called Prestopping, realizes noise-free training under any type of label noise for practical use. Extensive experiments using four image benchmark data sets verify that our method significantly outperforms four state-of-the-art methods in test error by 0.4–8.2 percent points under existence of real-world noise.","tags":null,"title":"How Does Early Stopping Help Generalization against Label Noise? (ICMLW 2020)","type":"publication"},{"authors":["Sundong Kim","Hwanjun Song","Sejin Kim","Beomyoung Kim","Jae-Gil Lee"],"categories":null,"content":"","date":1579478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579478400,"objectID":"b7b895e292892ada50a248e554dbfa19","permalink":"https://example.com/publication/2020pakdd_revisit/","publishdate":"2020-01-20T00:00:00Z","relpermalink":"/publication/2020pakdd_revisit/","section":"publication","summary":"In this manuscript, we introduce SurvRev, a next-generation revisit prediction model that can be tested directly in the business. The SurvRev model has many advantages. First, SurvRev can use partial observations which were considered as missing data and removed in the previous regression framework. By using deep survival analysis, we are able to estimate the next customer arrival from unknown distribution. Second, SurvRev is an event rate prediction model. It generates the predicted event rate of the next k days rather than predicting revisit interval and revisit intention directly. We showed the superiority of the SurvRev model by comparing with diverse baselines including the feature engineering model and the state-of-the-art deep survival models.","tags":null,"title":"Revisit Prediction by Deep Survival Analysis (PAKDD 2020)","type":"publication"},{"authors":["Dongmin Park","Hwanjun Song","Minseok Kim","Jae-Gil Lee"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"d7b4520c387fdf531c0fc45e72e1fbd9","permalink":"https://example.com/publication/2020thewebconf_trap/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/2020thewebconf_trap/","section":"publication","summary":"Finding low-dimensional embeddings of sparse high-dimensional data objects is important in many applications such as recommendation, graph mining, and natural language processing (NLP). Recently, autoencoder (AE)-based embedding approaches have achieved state-of-the-art performance in many tasks, especially in top-k recommendation tasks with user embedding or node classification tasks with node embedding. However, we find that many real-world data follow the power-law distribution with respect to the data object sparsity. When learning AE-based embeddings of these data, dense inputs move away from sparse inputs in an embedding space even when they are highly correlated. Resultingly, the embedding is distorted, which we call the polarization problem. In this paper, we propose TRAP that leverages two-level regularizers to effectively alleviate this problem. (i) The macroscopic regularizer adds a regularization term in the loss function to generally prevent dense input objects from being distant from other sparse input objects. (ii) The microscopic regularizer introduces a new object-wise parameter to individually entice each object to correlated neighbor objects rather than uncorrelated ones. Importantly, TRAP is a meta-algorithm that can be easily coupled with existing AE-based embedding methods with a simple modification. In extensive experiments on two representative embedding tasks using six-real world datasets, TRAP boosted the performance of the state-of-the-art algorithms by up to 31.53% and 94.99% respectively.","tags":null,"title":"TRAP: Two-level Regularized Autoencoder-based Embedding for Power-law Distributed Data (TheWebConf 2020)","type":"publication"},{"authors":["Hwanjun Song","Minseok Kim","Sundong Kim","Jae-Gil Lee"],"categories":null,"content":"","date":1574121600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574121600,"objectID":"1180f6bfd7adf4245ea5c5763f27cff4","permalink":"https://example.com/publication/2019arxiv_carpediem/","publishdate":"2019-11-19T00:00:00Z","relpermalink":"/publication/2019arxiv_carpediem/","section":"publication","summary":"The performance of deep neural networks is significantly affected by how well mini-batches are constructed. In this paper, we propose a novel adaptive batch selection algorithm called Recency Bias that exploits the uncertain samples predicted inconsistently in recent iterations. The historical label predictions of each sample are used to evaluate its predictive uncertainty within a sliding window. By taking advantage of this design, Recency Bias not only accelerates the training step but also achieves a more accurate network. We demonstrate the superiority of Recency Bias by extensive evaluation on two independent tasks. Compared with existing batch selection methods, the results showed that Recency Bias reduced the test error by up to 20.5% in a fixed wall-clock training time. At the same time, it improved the training time by up to 59.3% to reach the same test error","tags":null,"title":"Carpe Diem, Seize the Samples Uncertain \"At the Moment\" for Adaptive Batch Selection (Arxiv 2019)","type":"publication"},{"authors":["Dongmin Park","Susik Yoon","Hwanjun Song","Jae-Gil Lee"],"categories":null,"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"2536f805ec48783f256aa75d550bd686","permalink":"https://example.com/publication/2019kdd_mlat/","publishdate":"2019-08-01T00:00:00Z","relpermalink":"/publication/2019kdd_mlat/","section":"publication","summary":"Learning a good distance measure for distance-based classification in time series leads to significant performance improvement in many tasks. Specifically, it is critical to effectively deal with variations and temporal dependencies in time series. However, existing metric learning approaches focus on tackling variations mainly using a strict alignment of two sequences, thereby being not able to capture temporal dependencies. To overcome this limitation, we propose MLAT, which covers both alignment and temporal dependencies at the same time. MLAT achieves the alignment effect as well as preserves temporal dependencies by augmenting a given time series using a sliding window. Furthermore, MLAT employs time-invariant metric learning to derive the most appropriate distance measure from the augmented samples which can also capture the temporal dependencies among them well. We show that MLAT outperforms other existing algorithms in the extensive experiments on various real-world data sets.","tags":null,"title":"MLAT: Metric Learning for kNN in Streaming Time Series (KDDW 2019)","type":"publication"},{"authors":["Hwanjun Song","Minseok Kim","Jae-Gil Lee"],"categories":null,"content":"","date":1560556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560556800,"objectID":"0c81d0a89eae749812835a2035017a04","permalink":"https://example.com/publication/2019icml_selfie/","publishdate":"2019-06-15T00:00:00Z","relpermalink":"/publication/2019icml_selfie/","section":"publication","summary":"Owing to the extremely high expressive power of deep neural networks, their side effect is to totally memorize training data even when the labels are extremely noisy. To overcome overfitting on the noisy labels, we propose a novel robust training method called SELFIE. Our key idea is to selectively refurbish and exploit unclean samples that can be corrected with high precision, thereby gradually increasing the number of available training samples. Taking advantage of this design, SELFIE effectively prevents the risk of noise accumulation from the false correction and fully exploits the training data. To validate the superiority of SELFIE, we conducted extensive experimentation using four real-world or synthetic data sets. The result showed that SELFIE remarkably improved absolute test error compared with two state-of-the-art methods.","tags":null,"title":"SELFIE: Refurbishing Unclean Samples for Robust Deep Learning (ICML 2019)","type":"publication"},{"authors":["Hwanjun Song","Jae-Gil Lee"],"categories":null,"content":"","date":1528588800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528588800,"objectID":"d079f0af428af258ee6005bf7fcc8852","permalink":"https://example.com/publication/2018sigmod_rpdbscan/","publishdate":"2018-06-10T00:00:00Z","relpermalink":"/publication/2018sigmod_rpdbscan/","section":"publication","summary":"In most parallel DBSCAN algorithms, neighboring points are assigned to the same data partition for parallel processing to facilitate calculation of the density of the neighbors. This data partitioning scheme causes a few critical problems including load imbalance between data partitions, especially in a skewed data set. To remedy these problems, we propose a cell-based data partitioning scheme, pseudo random partitioning , that randomly distributes small cells rather than the points themselves. It achieves high load balance regardless of data skewness while retaining the data contiguity required for DBSCAN. In addition, we build and broadcast a highly compact summary of the entire data set, which we call a two-level cell dictionary , to supplement random partitions. Then, we develop a novel parallel DBSCAN algorithm, Random Partitioning-DBSCAN (shortly, RP-DBSCAN), that uses pseudo random partitioning together with a two-level cell dictionary. The algorithm simultaneously finds the local clusters to each data partition and then merges these local clusters to obtain global clustering. To validate the merit of our approach, we implement RP-DBSCAN on Spark and conduct extensive experiments using various real-world data sets on 12 Microsoft Azure machines (48 cores). In RP-DBSCAN, data partitioning and cluster merging are very light, and clustering on each split is not dragged out by a specific worker. Therefore, the performance results show that RP-DBSCAN significantly outperforms the state-of-the-art algorithms by up to 180 times.","tags":null,"title":"RP-DBSCAN: A Superfast Parallel DBSCAN Algorithm based on Random Partitioning (SIGMOD 2018)","type":"publication"},{"authors":["Hwanjun Song","Jae-Gil Lee","Wook-Shin Han"],"categories":null,"content":"","date":1502582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502582400,"objectID":"f5b65c3c512c9434b689193e59f7644b","permalink":"https://example.com/publication/2017kdd_pamae/","publishdate":"2017-08-13T00:00:00Z","relpermalink":"/publication/2017kdd_pamae/","section":"publication","summary":"The k-medoids algorithm is one of the best-known clustering algorithms. Despite this, however, it is not as widely used for big data analytics as the k-means algorithm, mainly because of its high computational complexity. Many studies have attempted to solve the efficiency problem of the k-medoids algorithm, but all such studies have improved efficiency at the expense of accuracy. In this paper, we propose a novel parallel k-medoids algorithm, which we call PAMAE, that achieves both high accuracy and high efficiency. We identify two factors \\\"global search\\\" and \\\"entire data\\\" that are essential to achieving high accuracy, but are also very time-consuming if considered simultaneously. Thus, our key idea is to apply them individually through two phases, parallel seeding and parallel refinement, neither of which is costly. The first phase performs global search over sampled data, and the second phase performs local search over entire data. Our theoretical analysis proves that this serial execution of the two phases leads to an accurate solution that would be achieved by global search over entire data. In order to validate the merit of our approach, we implement PAMAE on Spark as well as Hadoop and conduct extensive experiments using various real-world data sets on 12 Microsoft Azure machines (48 cores). The results show that PAMAE significantly outperforms most of recent parallel algorithms and, at the same time, produces a clustering quality as comparable as the previous most-accurate algorithm.","tags":null,"title":"PAMAE: Parallel k-Medoids Clustering with High Accuracy and Efficiency (KDD 2017)","type":"publication"}]