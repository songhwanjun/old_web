[{"authors":["admin"],"categories":null,"content":"I am a forth-year Ph.D candidate in Graduate School of Knowledge Service Engineering at KAIST. Currently, my advisor is Prof. Jae-Gil Lee, and I am a representative student in Data Mining Lab.\nNow, I am working on a research project as a research intern (Google Research, 2020 July \u0026ndash; December) under the supervision of two hosts, Eunyoung Kim and Ming-Hsuan Yang, and two mentors,Dr. Deqing Sun and Dr. Varun Jampani.\nMy general research interests lie in improving the performance of machine learning (ML) techniques under real-world scenarios. I am particularly interested in designing more advanced approaches to handle large-scale and noisy data, which are two main real-world challenges to hinder the practical use of ML approaches.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a forth-year Ph.D candidate in Graduate School of Knowledge Service Engineering at KAIST. Currently, my advisor is Prof. Jae-Gil Lee, and I am a representative student in Data Mining Lab.\nNow, I am working on a research project as a research intern (Google Research, 2020 July \u0026ndash; December) under the supervision of two hosts, Eunyoung Kim and Ming-Hsuan Yang, and two mentors,Dr. Deqing Sun and Dr. Varun Jampani.","tags":null,"title":"Hwanjun Song","type":"authors"},{"authors":["Hwanjun Song","Minseok Kim","Sundong Kim","Jae-Gil Lee"],"categories":null,"content":"","date":1594944000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594944000,"objectID":"2bbeb8e242838053624af1fcd60bb781","permalink":"/publication/2020cikm_carpediem/","publishdate":"2020-07-17T00:00:00Z","relpermalink":"/publication/2020cikm_carpediem/","section":"publication","summary":"The accuracy of deep neural networks is significantly affected by how well mini-batches are constructed during the training step. In this paper, we propose a novel adaptive batch selection algorithm called RecencyBias that exploits the uncertain samples predicted inconsistently in recent iterations. The historical label predictions of each training sample are used to evaluate its predictive uncertainty within a sliding window. Then, the sampling probability for the next mini-batch is assigned to each training sample in proportion to its  predictive uncertainty. By taking advantage of this design, Recency Bias not only accelerates the training step but also achieves a more accurate network. We demonstrate the superiority of Recency Bias by extensive evaluation on two independent tasks. Compared with existing batch selection methods, the results showed that Recency Bias reduced the test error by up to 20.97% in a fixed wall-clock training time. At the same time, it improved the training time by up to 59.32% to reach the same test error.","tags":null,"title":"Carpe Diem, Seize the Samples Uncertain \"At the Moment\" for Adaptive Batch Selection (CIKM 2020)","type":"publication"},{"authors":["Hwanjun Song","Sundong Kim","Minseok Kim","Jae-Gil Lee"],"categories":null,"content":"","date":1594857600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594857600,"objectID":"b3ee87337bec1e64ae65cb7780bdb038","permalink":"/publication/2020ml_ada/","publishdate":"2020-07-17T00:00:00Z","relpermalink":"/publication/2020ml_ada/","section":"publication","summary":"Neural networks converge faster with help from a smart batch selection strategy. In this regard, we propose Ada-Boundary, a novel and simple adaptive batch selection algorithm that constructs an effective mini-batch according to the learning progress of the model. Our key idea is to exploit confusing samples for which the model cannot predict labels with high confidence. Thus, samples near the current decision boundary are considered to be the most effective for expediting convergence. Taking advantage of this design, Ada-Boundary maintained its dominance for various degrees of training difficulty. We demonstrate the advantage of Ada-Boundary by extensive experimentation using CNNs with five benchmark data sets. Ada-Boundary was shown to produce a relative improvement in test errors by up to 31.80% compared with the baseline for a fixed wall-clock training time, thereby achieving a faster convergence speed.","tags":null,"title":"Ada-Boundary: Accelerating DNN Training via Adaptive Boundary Batch Selection (Machine Learning 2020, SCIE IF=2.672, ECML-PKDD journal track)","type":"publication"},{"authors":["Hwanjun Song","Minseok Kim","Dongmin Park","Jae-Gil Lee"],"categories":null,"content":"","date":1594857600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594857600,"objectID":"fea2d4c3722982ba572b7e01aaf2588a","permalink":"/publication/2020arxiv_survey/","publishdate":"2020-07-16T00:00:00Z","relpermalink":"/publication/2020arxiv_survey/","section":"publication","summary":"Deep learning has achieved remarkable success in numerous domains with help from large amounts of big data. However, the quality of data labels is a concern because of the lack of high-quality labels in many real-world scenarios. As noisy labels severely degrade the generalization performance of deep neural networks, learning from noisy labels (robust training) is becoming an important task in modern deep learning applications. In this survey, we first describe the problem of learning with label noise from a supervised learning perspective. Next, we provide a comprehensive review of 46 state-of-the-art robust training methods, all of which are categorized into seven groups according to their methodological difference, followed by a systematic comparison of six properties used to evaluate their superiority. Subsequently, we summarize the typically used evaluation methodology, including public noisy datasets and evaluation metrics. Finally, we present several promising research directions that can serve as a guideline for future studies.","tags":null,"title":"Learning from Noisy Labels with Deep Neural Networks: A Survey (Arxiv 2020, Under Review)","type":"publication"},{"authors":["Minseok Kim","Junhyeok Kang","Doyoung Kim","Hwanjun Song","Hyangsuk Min","Youngeun Nam","Dongmin Park","Jae-Gil Lee"],"categories":null,"content":"","date":1594771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594771200,"objectID":"eb0bf35f66d270bfaf939de171680077","permalink":"/publication/2020kdd_hicovidnet/","publishdate":"2020-07-15T00:00:00Z","relpermalink":"/publication/2020kdd_hicovidnet/","section":"publication","summary":"The escalating crisis of COVID-19 has put people all over the world in danger. Owing to the high contagion rate of the virus, COVID-19 cases continue to increase globally. To further suppress the threat of the COVID-19 pandemic and minimize its damage, it is imperative that each country monitors inbound travelers. Moreover, given that resources for quarantine are often limited, they must be carefully allocated. In this paper, to aid in such allocation by predicting the number of inbound COVID-19 cases, we propose Hi-COVIDNet, which takes advantage of the geographic hierarchy. Hi-COVIDNet is based on a neural network with two-level components, namely, country-level and continent-level encoders, which understand the complex relationships among foreign countries and derive their respective contagion risk to the destination country. An in-depth case study in South Korea with real-world COVID-19 datasets confirmed the effectiveness and practicality of Hi-COVIDNet. The source code and datasets are available at https://bit.ly/3gDLsCT.","tags":null,"title":"Hi-COVIDNet: Deep Learning Approach to Predict Inbound COVID-19 Patients and Case Study in South Korea (KDD 2020)","type":"publication"},{"authors":["Hwanjun Song","Minseok Kim","Dongmin Park","Jae-Gil Lee"],"categories":null,"content":"","date":1594600800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594600800,"objectID":"d971fa0f49ba6aefb56c61abb07b67e1","permalink":"/publication/2019arxiv_prestopping/","publishdate":"2020-07-13T00:40:00Z","relpermalink":"/publication/2019arxiv_prestopping/","section":"publication","summary":"Noisy labels are very common in real-world training data, which lead to poor generalization on test data because of overfitting to the noisy labels. In this paper, we claim that such overfitting can be avoided by “early stopping” training a deep neural network before the noisy labels are severely memorized. Then, we resume training the early stopped network using a “maximal safe set,” which maintains a collection of almost certainly true-labeled samples at each epoch since the early stop point. Putting them all together, our novel two-phase training method, called Prestopping, realizes noise-free training under any type of label noise for practical use. Extensive experiments using four image benchmark data sets verify that our method significantly outperforms four state-of-the-art methods in test error by 0.4–8.2 percent points under existence of real-world noise.","tags":null,"title":"How Does Early Stopping Help Generalization against Label Noise? (ICMLW 2020)","type":"publication"},{"authors":["Sundong Kim","Hwanjun Song","Sejin Kim","Beomyoung Kim","Jae-Gil Lee"],"categories":null,"content":"","date":1579478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579478400,"objectID":"b7b895e292892ada50a248e554dbfa19","permalink":"/publication/2020pakdd_revisit/","publishdate":"2020-01-20T00:00:00Z","relpermalink":"/publication/2020pakdd_revisit/","section":"publication","summary":"In this manuscript, we introduce SurvRev, a next-generation revisit prediction model that can be tested directly in the business. The SurvRev model has many advantages. First, SurvRev can use partial observations which were considered as missing data and removed in the previous regression framework. By using deep survival analysis, we are able to estimate the next customer arrival from unknown distribution. Second, SurvRev is an event rate prediction model. It generates the predicted event rate of the next k days rather than predicting revisit interval and revisit intention directly. We showed the superiority of the SurvRev model by comparing with diverse baselines including the feature engineering model and the state-of-the-art deep survival models.","tags":null,"title":"Revisit Prediction by Deep Survival Analysis (PAKDD 2020)","type":"publication"},{"authors":["Dongmin Park","Hwanjun Song","Minseok Kim","Jae-Gil Lee"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"d7b4520c387fdf531c0fc45e72e1fbd9","permalink":"/publication/2020thewebconf_trap/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/2020thewebconf_trap/","section":"publication","summary":"Finding low-dimensional embeddings of sparse high-dimensional data objects is important in many applications such as recommendation, graph mining, and natural language processing (NLP). Recently, autoencoder (AE)-based embedding approaches have achieved state-of-the-art performance in many tasks, especially in top-k recommendation tasks with user embedding or node classification tasks with node embedding. However, we find that many real-world data follow the power-law distribution with respect to the data object sparsity. When learning AE-based embeddings of these data, dense inputs move away from sparse inputs in an embedding space even when they are highly correlated. Resultingly, the embedding is distorted, which we call the polarization problem. In this paper, we propose TRAP that leverages two-level regularizers to effectively alleviate this problem. (i) The macroscopic regularizer adds a regularization term in the loss function to generally prevent dense input objects from being distant from other sparse input objects. (ii) The microscopic regularizer introduces a new object-wise parameter to individually entice each object to correlated neighbor objects rather than uncorrelated ones. Importantly, TRAP is a meta-algorithm that can be easily coupled with existing AE-based embedding methods with a simple modification. In extensive experiments on two representative embedding tasks using six-real world datasets, TRAP boosted the performance of the state-of-the-art algorithms by up to 31.53% and 94.99% respectively.","tags":null,"title":"TRAP: Two-level Regularized Autoencoder-based Embedding for Power-law Distributed Data (TheWebConf 2020)","type":"publication"},{"authors":["Dongmin Park","Susik Yoon","Hwanjun Song","Jae-Gil Lee"],"categories":null,"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"2536f805ec48783f256aa75d550bd686","permalink":"/publication/2019kdd_mlat/","publishdate":"2019-08-01T00:00:00Z","relpermalink":"/publication/2019kdd_mlat/","section":"publication","summary":"Learning a good distance measure for distance-based classification in time series leads to significant performance improvement in many tasks. Specifically, it is critical to effectively deal with variations and temporal dependencies in time series. However, existing metric learning approaches focus on tackling variations mainly using a strict alignment of two sequences, thereby being not able to capture temporal dependencies. To overcome this limitation, we propose MLAT, which covers both alignment and temporal dependencies at the same time. MLAT achieves the alignment effect as well as preserves temporal dependencies by augmenting a given time series using a sliding window. Furthermore, MLAT employs time-invariant metric learning to derive the most appropriate distance measure from the augmented samples which can also capture the temporal dependencies among them well. We show that MLAT outperforms other existing algorithms in the extensive experiments on various real-world data sets.","tags":null,"title":"MLAT: Metric Learning for kNN in Streaming Time Series (KDDW 2019)","type":"publication"},{"authors":["Hwanjun Song","Minseok Kim","Jae-Gil Lee"],"categories":null,"content":"","date":1560556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560556800,"objectID":"0c81d0a89eae749812835a2035017a04","permalink":"/publication/2019icml_selfie/","publishdate":"2019-06-15T00:00:00Z","relpermalink":"/publication/2019icml_selfie/","section":"publication","summary":"Owing to the extremely high expressive power of deep neural networks, their side effect is to totally memorize training data even when the labels are extremely noisy. To overcome overfitting on the noisy labels, we propose a novel robust training method called SELFIE. Our key idea is to selectively refurbish and exploit unclean samples that can be corrected with high precision, thereby gradually increasing the number of available training samples. Taking advantage of this design, SELFIE effectively prevents the risk of noise accumulation from the false correction and fully exploits the training data. To validate the superiority of SELFIE, we conducted extensive experimentation using four real-world or synthetic data sets. The result showed that SELFIE remarkably improved absolute test error compared with two state-of-the-art methods.","tags":null,"title":"SELFIE: Refurbishing Unclean Samples for Robust Deep Learning (ICML 2019)","type":"publication"},{"authors":["Hwanjun Song","Jae-Gil Lee"],"categories":null,"content":"","date":1528588800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528588800,"objectID":"d079f0af428af258ee6005bf7fcc8852","permalink":"/publication/2018sigmod_rpdbscan/","publishdate":"2018-06-10T00:00:00Z","relpermalink":"/publication/2018sigmod_rpdbscan/","section":"publication","summary":"In most parallel DBSCAN algorithms, neighboring points are assigned to the same data partition for parallel processing to facilitate calculation of the density of the neighbors. This data partitioning scheme causes a few critical problems including load imbalance between data partitions, especially in a skewed data set. To remedy these problems, we propose a cell-based data partitioning scheme, pseudo random partitioning , that randomly distributes small cells rather than the points themselves. It achieves high load balance regardless of data skewness while retaining the data contiguity required for DBSCAN. In addition, we build and broadcast a highly compact summary of the entire data set, which we call a two-level cell dictionary , to supplement random partitions. Then, we develop a novel parallel DBSCAN algorithm, Random Partitioning-DBSCAN (shortly, RP-DBSCAN), that uses pseudo random partitioning together with a two-level cell dictionary. The algorithm simultaneously finds the local clusters to each data partition and then merges these local clusters to obtain global clustering. To validate the merit of our approach, we implement RP-DBSCAN on Spark and conduct extensive experiments using various real-world data sets on 12 Microsoft Azure machines (48 cores). In RP-DBSCAN, data partitioning and cluster merging are very light, and clustering on each split is not dragged out by a specific worker. Therefore, the performance results show that RP-DBSCAN significantly outperforms the state-of-the-art algorithms by up to 180 times.","tags":null,"title":"RP-DBSCAN: A Superfast Parallel DBSCAN Algorithm based on Random Partitioning (SIGMOD 2018)","type":"publication"},{"authors":["Hwanjun Song","Jae-Gil Lee","Wook-Shin Han"],"categories":null,"content":"","date":1502582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502582400,"objectID":"f5b65c3c512c9434b689193e59f7644b","permalink":"/publication/2017kdd_pamae/","publishdate":"2017-08-13T00:00:00Z","relpermalink":"/publication/2017kdd_pamae/","section":"publication","summary":"The k-medoids algorithm is one of the best-known clustering algorithms. Despite this, however, it is not as widely used for big data analytics as the k-means algorithm, mainly because of its high computational complexity. Many studies have attempted to solve the efficiency problem of the k-medoids algorithm, but all such studies have improved efficiency at the expense of accuracy. In this paper, we propose a novel parallel k-medoids algorithm, which we call PAMAE, that achieves both high accuracy and high efficiency. We identify two factors \\\"global search\\\" and \\\"entire data\\\" that are essential to achieving high accuracy, but are also very time-consuming if considered simultaneously. Thus, our key idea is to apply them individually through two phases, parallel seeding and parallel refinement, neither of which is costly. The first phase performs global search over sampled data, and the second phase performs local search over entire data. Our theoretical analysis proves that this serial execution of the two phases leads to an accurate solution that would be achieved by global search over entire data. In order to validate the merit of our approach, we implement PAMAE on Spark as well as Hadoop and conduct extensive experiments using various real-world data sets on 12 Microsoft Azure machines (48 cores). The results show that PAMAE significantly outperforms most of recent parallel algorithms and, at the same time, produces a clustering quality as comparable as the previous most-accurate algorithm.","tags":null,"title":"PAMAE: Parallel k-Medoids Clustering with High Accuracy and Efficiency (KDD 2017)","type":"publication"}]